# Self-Supervised Learning â€” Research-Oriented Topics (Level 5)

This module implements key concepts in **Self-Supervised Learning (SSL)**, where representations are learned from the data itself without explicit external labels.

## ðŸ“Œ Module Scope

- **Contrastive Learning**: Implementing the InfoNCE (SimCLR-style) loss function.
- **Masked Prediction**: Demonstrating how models learn by predicting masked parts of the input (BERT/MAE style).
- **SSL vs Supervised Comparison**: Conceptual analysis of feature quality.

---

## ðŸ“‚ Repository Structure

```text
self-supervised-learning/
â”‚
â”œâ”€â”€ contrastive_loss.py        # InfoNCE loss implementation
â”œâ”€â”€ masked_prediction.py       # Input masking and reconstruction logic
â”œâ”€â”€ ssl_vs_supervised.py       # Performance comparison metrics
â”œâ”€â”€ utils.py                   # Data augmentation helpers
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
