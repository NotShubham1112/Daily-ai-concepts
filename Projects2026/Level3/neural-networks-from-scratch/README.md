# Neural Networks from Scratch â€” Deep Learning Foundations (Level 3)

This module implements **Neural Networks completely from scratch**, focusing on the mathematical and algorithmic foundations of deep learning.

All components â€” forward propagation, backpropagation, activation functions, and gradient flow â€” are implemented using **NumPy only**, without relying on deep learning frameworks such as PyTorch or TensorFlow.

This module serves as the **bridge between classical machine learning and modern deep learning systems**.

---

## ðŸ“Œ Module Scope

This module covers:

- Fully connected (dense) neural networks
- Forward propagation
- Backpropagation via chain rule
- Activation functions and their gradients
- Gradient flow analysis
- Training dynamics and convergence behavior

---

## ðŸ“‚ Repository Structure

```text
neural-networks-from-scratch/
â”‚
â”œâ”€â”€ neural_network.py          # Core neural network + backpropagation
â”œâ”€â”€ activations.py             # Activation functions and gradients
â”œâ”€â”€ losses.py                  # Loss functions and derivatives
â”œâ”€â”€ gradient_visualization.py  # Gradient flow analysis per layer
â”œâ”€â”€ activation_study.py        # Activation function performance comparison
â”œâ”€â”€ utils.py                   # Helper utilities
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
