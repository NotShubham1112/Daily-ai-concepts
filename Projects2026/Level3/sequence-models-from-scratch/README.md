# ðŸ§  Sequence Models From Scratch (RNN, LSTM, Temporal Learning)

This repository implements **sequence models from first principles using NumPy only**, without relying on deep learning frameworks such as TensorFlow or PyTorch.

The goal is **conceptual mastery**, not abstraction.

---

## ðŸ“Œ Module Overview

**Sequence Models** are designed to process ordered data where **temporal dependency** matters.

Examples:
- Text
- Speech
- Time-series
- Sensor data
- Financial signals

This module covers:
- Vanilla Recurrent Neural Networks (RNNs)
- Long Short-Term Memory (LSTM) networks
- Temporal forward propagation
- Vanishing gradient problem
- Real-world sequence modeling tasks

---

## ðŸ“‚ Project Structure

```text
sequence-models-from-scratch/
â”‚
â”œâ”€â”€ rnn.py                     # Vanilla RNN implementation
â”œâ”€â”€ lstm.py                    # LSTM cell from scratch
â”œâ”€â”€ text_generation.py         # Character-level text generation
â”œâ”€â”€ time_series.py             # Time-series forecasting
â”œâ”€â”€ vanishing_gradients.py     # Gradient decay visualization
â”œâ”€â”€ utils.py                   # Helper functions
â”œâ”€â”€ requirements.txt           # Dependencies
â””â”€â”€ README.md                  # Documentation
