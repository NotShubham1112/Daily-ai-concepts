# Robust & Trustworthy Machine Learning â€” Research-Oriented Topics (Level 5)

This module focuses on the ethical and safety aspects of AI, including model robustness against attacks, interpretability, and bias mitigation.

## ðŸ“Œ Module Scope

- **Adversarial Robustness**: Implementing the Fast Gradient Sign Method (FGSM) to generate adversarial examples.
- **Model Interpretability**: Creating saliency maps to visualize which input features influence a model's decision.
- **Fairness & Bias**: Measuring Disparate Impact and Demographic Parity in model predictions.

---

## ðŸ“‚ Repository Structure

```text
robust-ml/
â”‚
â”œâ”€â”€ adversarial_attacks.py    # FGSM attack implementation
â”œâ”€â”€ interpretability.py        # Saliency maps and explanation logic
â”œâ”€â”€ fairness_metrics.py       # Bias detection tools
â”œâ”€â”€ utils.py                   # Gradient computation helpers
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
