# Decision Trees & Ensemble Methods â€” Classical Machine Learning (Level 2)

This module focuses on **tree-based learning algorithms**, which form the backbone of many high-performing classical machine learning systems used in industry and research.

All models in this repository are implemented **from scratch**, without relying on machine learning libraries such as `scikit-learn`, in order to build a precise understanding of how tree-based models learn, generalize, and scale.

---

## ðŸ“Œ Module Scope

This module covers:

- Decision Trees (Classification & Regression)
- Feature selection using information gain
- Ensemble learning principles
- Random Forest intuition
- Gradient Boosting fundamentals
- Biasâ€“variance behavior in ensembles

Only the following libraries are used:
- **NumPy** (numerical computation)
- **Matplotlib** (visualization)

---

## ðŸ“‚ Repository Structure

```text
decision-trees-ensemble/
â”‚
â”œâ”€â”€ decision_tree.py              # Decision Tree from scratch
â”œâ”€â”€ split_criteria.py             # Gini, Entropy, Information Gain
â”œâ”€â”€ feature_importance.py         # Feature importance analysis
â”œâ”€â”€ random_forest.py              # Random Forest (conceptual implementation)
â”œâ”€â”€ ensemble_bias_variance.py     # Biasâ€“variance study for ensembles
â”œâ”€â”€ utils.py                      # Helper functions
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
